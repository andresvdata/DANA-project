---
title: "Project"
author: "Team 1"
date: "2022-10-27"
output: pdf_document
---

#### Load the data

```{r}
df<-read.csv('googleplaystore.csv')
#View(df)
```



```{r}
df[df$Reviews==0 & is.na(df$Rating) ,]
```



```{r}
colSums((is.na(df)) | (df=='') | (df=='NaN'))
```

Now, we will replace '' and 'NaN' to null values

```{r}
df[df=='']<-NA
df[(df=='NaN')]<-NA
```

```{r}
colSums((is.na(df)) )

```

NULL TREATMENT

since the null values of the attribute rating are higher than 10% of the sample. We cannot rid of these observations. So those values will be filled in.


As there are too many outliers, the mode was used for replacing the null values.
```{r}
mode(df$Rating[na.omit(df$Rating)]) #mode is  4.4

# create a originla copy of rating variable
df$Rating_original<-df$Rating 

df$Rating[is.na(df$Rating)]<-4.4
df$Rating_original[is.na(df$Rating_original)]<-'N'
```



```{r}
colSums((is.na(df)) )

```

In total there are 12 rows with missing values which represents less than 1% of the data.
```{r}
12/length(col(df))*100
```


As the null remaining are too small compared to the dataset. there missing value will be excluded using listwise method.

```{r}
df<-na.omit(df)
```

```{r}
colSums((is.na(df)) )
```

Let's check the null values in the dataframe.

There are not more missing values.
# quality data

Due to the price attribute format is incorrect, we should remove the dollar sign 

##price
```{r}
df$Price<-gsub('(\\$|,)','',df$Price)
```

##installs

```{r}
df$Installs<-gsub('(\\+|,)','',df$Installs)
```




```{r}
df$Category<- as.factor(df$Category)
df$Rating<- as.numeric(df$Rating)
df$Reviews<- as.numeric(df$Reviews)
df$Installs<- as.numeric(df$Installs)

df$Price<- as.numeric(df$Price)
```



The reason why we replace 'Varies with device' value from the size column is because it represents more than 15% of whole dataframe and eliminating these values would represent a significant loss in data changing them on the other hand is a necessary step to convert the values for categorical to numeric.


```{r}
df$App<- as.character(df$App)
df$Category<- as.factor(df$Category)
df$Rating<- as.numeric(df$Rating)
df$Reviews<- as.numeric(df$Reviews)
df$Price<- as.numeric(df$Price)
```




## duplicated:
```{r}
df_new<-df[!duplicated(df),]
df_new
```


These are the new results


```{r}
summary(df_new)
```

____________________


Question 2

•	How is the distribution of Rating? Can it be considered Normal distribution?
```{r}
hist(df_new$Rating, main='Histogram for Rating',xlab = 'Rating')
```





Question 3

As the price is a numerical variable we can describe the data by its central tendency, quartiles, variation and shape.
From the boxplot we can get a general view to describe the data:

```{r}
boxplot(df_new$Price)
```

This distribution its really right-skewed
```{r}
summary(df_new$Price)
```
This distribution shows various outliers.

```{r}
hist(df_new$Price)
```
distribution is right-skewed . there are many values in cero, they come from the free apps. Price variable should be analyzed for only app that are paid considering that for free apps will be always cero.
As there are app paid and not paid. This variable make sense analyze it only for apps are paid.

```{r}
pie(table(df_new$Type))
```

```{r}
df_new_paid=df_new[df_new$Type!='Free',]
df_new_free=df_new[df_new$Type=='Free',]
boxplot(df_new_paid$Price)
```



Even though the distribution is better, the presence of outliers are really high.



But first, lets check the treeshold to consider a value outlier to analize the ouliers...

```{r}
limit<-summary(df_new_paid$Price)[5]+1.5*IQR(df_new_paid$Price)
limit
```




```{r}
df_new_paid_l<- df_new_paid[(df_new_paid$Price<=limit),]
df_new_paid_g<- df_new_paid[(df_new_paid$Price>limit),]

```


```{r}
df_new[df_new$Reviews==0,]
```


```{r}
hist(df_new_paid_g$Price)
```
From the values considered ouliers from the distribution of paid apps, there are extreme values around 400. 



## fake apps
```{r}
df_new_paid_g[order(df_new_paid_g$Price,decreasing = TRUE),]
```
It looks like these apps are 'fake apps'. They do not do anything. They just cost a lot of money.
between  "I'm Rich - Trump Edition" to "I am rich VIP" from previous table can be considerd fake apps, how about apps high than 10 less than 200?


```{r}
df_new_paid_g_l200<- df_new_paid_g[df_new_paid_g$Price<=200,]
df_new_paid_g_l200<-df_new_paid_g_l200[order(df_new_paid_g_l200$Price,decreasing = TRUE),]
df_new_paid_g_l200
```
## fake and unvaluable apps
Among these apps, there is still one meme app 'I am rich Person', while the others looks to be 'serious apps'. Considering  some of these apps do not have any reviews or rating, the rest of them will be included.

```{r}
df_new_paid_g_okOutliers<- df_new_paid_g_l200[df_new_paid_g_l200$Reviews!=0 & df_new_paid_g_l200$Rating_original!='N'     ,]
df_new_paid_g_okOutliers
```

Once identified  the outliers, lets merge the data to data under price of 10.

```{r}
df_new_paid_clean<- merge(df_new_paid_g_okOutliers,df_new_paid_l,all=TRUE)
df_new_clean<- merge(df_new_paid_clean,df_new_free,all=TRUE)
df_new_clean
```


real price distribution . right-sweded
```{r}
boxplot(df_new_clean[df_new_clean$Type=='Paid',]$Price, main='Histogram for Price',xlab = 'Price')
```

# Question 4 

```{r}
data_model<-df_new_clean[df_new_clean$Reviews>0 & df_new_clean$Installs>0,]

plot(data_model$Installs~data_model$Reviews)

```
the variables seems to have logaritmict relation ship.

```{r}
plot(log(data_model$Installs)~log(data_model$Reviews))

```



```{r}
modelo<-lm(log(data_model$Installs)~log(data_model$Reviews),)
summary(modelo)
```




```{r}
plot(log(data_model$Installs)~log(data_model$Reviews))
abline(modelo)
```




question 3


Which are the 5 most expensive apps in the play store dataset? 

```{r}
df_top<-df_new_clean[order(-df_new_clean$Price),][1:9,]
df_top
```



Most expensive apps shows similar patron, the name has the word "Rich". These apps shouldnt be considered as real apps for the analyzis.
So the fakes app needs to be identified.

Considering that the most expensive apps relates the word "Rich" are more expensive than $200, the rest of app will be considered to answer this question and to answer subsequent questions.

These expensive values represent only 0.009%, so they can be deleted.
```{r}
length(df_new[df_new$Price<=200,])/length(col(df_new))*100
```


```{r}
df_new<-df_new[df_new$Price<=200,]
```






```{r}
mean(df_new$Rating)
```
```{r}
median(df_new$Rating)
```

```{r}
sd(df_new$Rating)
```



## 4 question

•	Can any of the numerical variables describe the behavior of the price tendency?




From this we have one hypothesis :
Ho= review and rating do not have a linear correlation among all subjects in the population

H1= Review and rating have a linear correlation among  all subjects in the population.


```{r}
app_paid[c("Price", "Reviews")]
```


```{r}
cor(df_new_clean$Reviews,df_new_clean$Installs)
plot(df$x, df$y, pch=19, xlim=c(0,30), ylim=c(0,150), main='Custom Axes')
#library(ggplot2)
#ggplot(subset(app_paid,aes(x=Price,y=Reviews)))+ geom_point()+scale_x_continuous(trans='log10')
```
there are outlierts for reviews



# question 5: We are suppose to compute the chik square for category and installs.

